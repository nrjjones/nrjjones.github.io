[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Information",
    "section": "",
    "text": "Nathan R. Jones, PhD\nSenior Project Director/Data Scientist\nUniversity of Wisconsin Survey Center (UWSC)\n4418 Sterling Hall\n475 N Charter St\nMadison, WI 53706-1582\nOffice: 608-890-4724\nnrjones@wisc.edu"
  },
  {
    "objectID": "org.html",
    "href": "org.html",
    "title": "Organization",
    "section": "",
    "text": "Your collaborators will appreciate your efforts to document every step of data cleaning, why you made analytic decisions, and how you organized your output, but your most thankful collaborator will be you in 2 years."
  },
  {
    "objectID": "org.html#the-basic-file-structure",
    "href": "org.html#the-basic-file-structure",
    "title": "Organization",
    "section": "The basic file structure",
    "text": "The basic file structure\n\n\n\nItem\nDescription\n\n\n\n\nREADME\nEssential info about the project\n\n\ncode.R\nAll steps for loading data, cleaning, analysis, and output\n\n\n/raw\nFolder for raw data, never altered\n\n\n/out\nFolder for altered data and other output\n\n\n/pst\nFolder for data or other output sent to others\n\n\n\nFor more complex projects, you might add a documentation folder (doc) and a makefile that runs several smaller R programs stored in /R.\n\n\n\nItem\nDescription\n\n\n\n\nREADME\nEssential info about the project\n\n\nmake.R\nCode to run programs in /R folder in order\n\n\n/R\nFolder for LoadData.R, CleanData.R, Analysis.R, Report.Rmd\n\n\n/raw\nFolder for raw data exactly as you received it\n\n\n/out\nFolder for altered data and other output\n\n\n/pst\nFolder for data or other output sent to others\n\n\n/doc\nFolder for documentation, codebooks, etc"
  },
  {
    "objectID": "org.html#git-and-github",
    "href": "org.html#git-and-github",
    "title": "Organization",
    "section": "git and Github",
    "text": "git and Github\nAn excellent conceptual introduction and set up guide by Jenny Bryan - Happy git and GitHub for the useR\nA webinar on using these tools from RStudio - Managing Change in RStudio"
  },
  {
    "objectID": "reporting.html",
    "href": "reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "IN PROGRESS\n\n\nFrequency tables\n\nfrtab <- function(df, x) {\n  tmp <- df %>%\n    select({{x}}) %>%\n    ftable() %>%\n    as.data.frame() %>%\n    mutate(\n      pct = scales::percent(Freq/sum(Freq), accuracy = 0.1),\n      `Percent (N)` = paste0(pct, \" (\", Freq, \")\")\n    ) %>%\n    select(-Freq, -pct) %>%\n    kable()\n\n  tmp\n}\n\n\n\nCATA tables\n\ncatatab <- function(df, x, stub) {\n  tmp <- df %>%\n    select(contains(x)) %>%\n    pivot_longer(\n      everything(),\n      names_to = \"var\",\n      values_to = \"val\"\n    ) %>%\n    mutate(\n      val = case_when(\n        !is.na(val) ~ \"Selected\",\n        is.na(val) ~ \"Not selected\"\n      )\n    ) %>%\n    group_by(var, val) %>%\n    tally() %>%\n    group_by(var) %>%\n    mutate(\n      N=sum(n),\n      perc = n/N,\n      Percent = sprintf(\"%.1f%s\", signif(perc*100, 3), \"%\"),\n      `Percent(N)` = paste0(Percent, \" (\", n, \")\")\n    ) %>%\n    select(-c(perc, n, N)) %>%\n    ungroup()\n\n\n  if(length(tmp$var) > 0) {\n\n    tmp <- left_join(tmp, varlist) %>%\n      select(Question=labels, val, `Percent(N)`) %>%\n      ungroup()\n\n    tmp$Question <- str_remove(tmp$Question, stub)\n\n    tmp <- pivot_wider(\n      tmp,\n      names_from = val,\n      values_from = `Percent(N)`\n    ) %>%\n      select(Question, Selected)\n\n    names(tmp) <- paste0(names(tmp), \" Percent(N)\")\n    names(tmp)[1] <- \"Response\"\n\n    tmp[is.na(tmp)] <- \"0.0%(0)\"\n\n    kable(tmp)\n  }\n}\n\n\n\n“Codebook” tables based on col number for easy looping\n\ncbtab <- function(df, x) {\n  tmp <- df %>%\n    select(names(df)[x]) %>%\n    ftable() %>%\n    as.data.frame() %>%\n    mutate(\n      pct = scales::percent(Freq/sum(Freq), accuracy = 0.1),\n      `Percent (N)` = paste0(pct, \" (\", Freq, \")\")\n    ) %>%\n    select(-Freq, -pct) %>%\n    kable()\n\n  tmp\n}\n\n\n\nFull datafile frequency report with cleaned variable labels\n\ncodebk <- function(x, df, varlist) {\n\n  rpt <- x\n  # Report generation\n  sink(rpt)  # Sink redirects output to write a Rmd file\n\n  # Report header\n  cat(\"--- \\n\")\n  tmp <- paste0(\"title: \\\"\", str_remove(rpt, \".qmd\"), \"\\\"\\n\")\n  cat(tmp)\n  cat(\"output: word_document \\n\")\n  cat(\"--- \\n\\n\")\n\n  # Report body\n\n  cat(\"```{r , results='asis', echo=FALSE, message=FALSE, warning=FALSE} \\n\")\n  cat(\"library(tidyverse) \\n\")\n  cat(\"library(stringr) \\n\")\n  cat(\"library(knitr) \\n\")\n  cat(\"options(xtable.comment=FALSE) \\n\")\n  cat(\"source(\\\"load_data.R\\\") \\n\")\n  cat(\"\\n\\n\")\n  cat(\"# Add extra filters to df here \\n\")\n  cat(\"\\n\\n\")\n  cat(\"``` \\n\\n\")\n\n  # Only categorical vars\n\n  for(i in 1:length(df)) {\n\n    tmp1 <- paste0(\"## \", varlist$var[i], \": \" , varlist$labels[[i]])\n    cat(tmp1)\n    cat(\"\\n\\n\")\n    cat(\"```{r , echo=FALSE, message=FALSE} \\n\\n\")\n    cat(\"cbtab( df, \",i,\" ) \\n\")\n    cat(\"``` \\n\\n\")\n  }\n\n  sink()  # Return output to console\n}\n\n\n\nOE export\n\nopenend <- function(oe, x, pnum) {\n  tmp <- oe[x]\n  names(tmp) <- \"Verbatim Response\"\n  tmp <- tmp %>% filter(`Verbatim Response` != \"\")\n  write_csv(tmp, paste0(\"./out/\", pnum, \" \", oev$var[x], \" Responses \", Sys.Date(), \".csv\"), na=\"\")\n\n}\n\n\n\nClient update reports\n\n\nCreate/Update an incentive list and payment log\n\n\nMail merge for gift code delivery\n\n\nZip for delivery and post to Box\n\n\nAutomate it all"
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "Functions",
    "section": "",
    "text": "Toy example\nThe most challenging thing about writing functions in R is the concept of scoping and environments, mostly meaning what things are called and where they are stored. Many, many tutorials and examples are written by stats or math people or programmers who don’t use typical social science data. So you see these toy examples like https://www.tutorialspoint.com/r/r_functions.htm\n\n    # Create a function with arguments.\n    new.function <- function(a,b,c) {\n       result <- a * b + c\n       print(result)\n    }\n\n    # Call the function by position of arguments.\n    new.function(5,3,11)\n\nSo simple! But nobody we work with needs or writes functions like that. With structured data, functions are harder to write because R doesn’t want you to make a mistake by referring to something in a different scope or environment. It used to be very ugly to code functions with our kind of data, but fairly recently, the tidyverse people came up with using double curly brackets to make it less ugly.\nHow do curly brackets work?\nOne commenter covers hours of frustration:\n\nRonak, so the {{}} is used to replace the enquo() and !! operators?\n\nHopefully, you’ll never have to know what that means, but if you are curious, this explains:\nrlang 0.4.0 release notes\n\n\nDouble curly brackets\nHow does this look in practice? Here’s a function I wrote to create nice looking crosstabs:\n\n    ctab <- function(x,y) {\n\n      tmp <- df %>%\n        filter(!is.na({{x}}))\n\n      tmp <- droplevels(tmp)\n\n      tmp2 <- tabyl(tmp, {{x}}, {{y}}) %>%\n        adorn_totals(c(\"col\", \"row\")) %>%\n        adorn_percentages(\"col\") %>%\n        adorn_pct_formatting() %>%\n        adorn_ns()\n\n      tmp2 <- kable(tmp2)\n\n      return(tmp2)\n    }\n\nThis combines a little cleaning I wanted to do on a lot of variables (removing blanks, dropping unused factor levels so you don’t get a lot of 0s in the table) and uses a nice function tabyl() from the janitor package to add n/% and kable() to make a formatted table. You can now write crosstabs like this\n\nctab(Q5, Q12r)\n\nwhere Q5 is some Yes/No question and Q12r is recoded categorical age and the output looks like this:\n\n\n\nQ5\n<14\n14-16\n17+\nTotal\n\n\n\n\nYes\n94.7% (18)\n88.2% (105)\n96.4% (54)\n91.2% (177)\n\n\nNo\n5.3% (1)\n5.0% (6)\n1.8% (1)\n4.1% (8)\n\n\nUnsure\n0.0% (0)\n6.7% (8)\n1.8% (1)\n4.6% (9)\n\n\nTotal\n100.0% (19)\n100.0% (119)\n100.0% (56)\n100.0% (194)\n\n\n\nYou could clean more by removing the Unsures from all tables that use this function by adding filter({{x}} != “Unsure” after the line that removes the missings, etc.\nThat function is a little quick and dirty because it assumes you always want to do crosstabs using a data object called “df”. If you had 7 data files loaded and wanted to be able to make crosstabs with several in a report, you could add a parameter for the data name like this\n\n    ctab <- function(df, x, y) {\n\n      tmp <- df %>%\n        filter(!is.na({{x}}))\n\n      tmp <- droplevels(tmp)\n\n      tmp2 <- tabyl(tmp, {{x}}, {{y}}) %>%\n        adorn_totals(c(\"col\", \"row\")) %>%\n        adorn_percentages(\"col\") %>%\n        adorn_pct_formatting() %>%\n        adorn_ns()\n\n      tmp2 <- kable(tmp2)\n\n      return(tmp2)\n    }\n\nThe function would be called with\n\nctab(df3, Q5, Q12r)\nctab(df4, Q5, Q12r)\n\nand so on to use on a specific data file.\n\n\nUsing functions with functions and loops\nAnd you can also call your function from other functions. Or you can use a loop to cycle through a bunch of variables. The following would print the function for all variables from the 2nd to the end in data file df (make Q12r the first variable so you don’t get a Q12r by Q12r line).\n\n    for(i in 2:length(df)) {\n      tmp <- paste0(\"ctab(df2, \", names(df)[i], \", Q12r)\")\n      cat(tmp, \"\\n\")\n    }\n\nGives you this:\n\nctab(df, Q2, Q12r) \nctab(df, Q3, Q12r)\nctab(df, Q4, Q12r)\nctab(df, Q5, Q12r)\nctab(df, Q6, Q12r)\nctab(df, Q7, Q12r)\nctab(df, Q8, Q12r)\nctab(df, Q9, Q12r) \n\n…\nOr you can can get fancy by adding the variable label too and now you basically have a report:\n\n    for(i in 2:length(df)) {\n      tmp1 <- attr(df[[i]], \"label\")\n      tmp2 <- paste0(\"ctab(df, \", names(df)[i], \", Q12r)\")\n      cat(tmp1, \"\\n\\n\", tmp2, \"\\n\\n\")  # \\n is a line break\n    }\n\nOutput:\n\nDo you have a transition plan?\nctab(df, Q3, Q12r)\nDid you help make your transition plan?\nctab(df, Q4, Q12r)\nDo you think having a transition plan is helpful?\nctab(df, Q5, Q12r)\n\nLast thing, there is a thing called Extract Function in the Code menu. In theory, you should be able to highlight a few lines of code that do something useful and it will just rewrite the code as a function. It works pretty well, but usually you would end up reorganizing your initial approach to write a function anyway, so I don’t find it too helpful.\n\n\nResources\nReasonably accessible\nhttps://dplyr.tidyverse.org/articles/programming.html\nMore details on the {{ }} functionality\nhttps://www.tidyverse.org/blog/2019/06/rlang-0-4-0/\nHadley’s function section - Still too complex for me\nhttps://r4ds.had.co.nz/functions.html"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Why use a Project?\nProjects are useful for creating a new space for your work. Think of it like a blank sheet of paper or, for more involved tasks, maybe a clean and stocked operating room. The working directory is automatically set to the project’s top level folder, and a .Rproj file can store information about your project.\nIf you are coming from Stata, you may be used to setting working directories to access and save files around your local or networked file structure. You can do that with R too using a command setwd(), but the R community considers this bad manners. They prefer to organize data, code, and tasks within a project-level directory for easier collaboration, very similar to the way UWSC already organizes project folders. This approach may be easier to adapt for newer, unaffiliated researchers who work with smaller and more portable data and harder for those who work on larger, collaborative projects that keep data in a single place.\nRStudio presentation about Projects"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UWSC Topics",
    "section": "",
    "text": "R for Project Directors\n\nGetting started with R\nRStudio projects\nFunctions\nSample Cleaning\nReporting\nWeighting\nFile organization\n\n\n\nOther\n\n2018 DemSem Presentation: Building contextual data\nPackage of functions to work with Qualtrics\nAbout"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Nathan R. Jones, PhD\nSenior Project Director/Data Scientist\nUniversity of Wisconsin Survey Center (UWSC)\n4418 Sterling Hall\n475 N Charter St\nMadison, WI 53706-1582\nOffice: 608-890-4724\nI am a Senior Project Director and Data Scientist at the University of Wisconsin Survey Center. My formal training is in demography and I have been a member of the Population Association of America since 1997. I have spent most of my career conducting population health research and providing methodological consultation to faculty, researchers, and students. Before moving to Wisconsin, I worked in the CDC’s Office on Smoking and Health, UCLA’s California Center for Population Research, and The RAND Corporation.\nAdditional publications on Google Scholar\nCV\n\nSelect Publications\n\nU.S. National Cancer Institute and World Health Organization. The Economics of Tobacco and Tobacco Control. National Cancer Institute Tobacco Control Monograph 21. NIH Publication No. 16-CA-8029A. Bethesda, MD: U.S. Department of Health and Human Services, National Institutes of Health, National Cancer Institute; and Geneva, CH: World Health Organization; 2016.\nDykema J, Jones NR, Piche T, Stevenson J. Surveying clinicians by web : current issues in design and administration. Eval Health Prof. 2013 Sep;36(3):352-81. doi: 10.1177/0163278713496630.\nLoConte N, Williamson A, Gayle A, Weiss J, Leal T, Cetnar J, Mohammed T, Tevaarwerk A, Jones NR. Increasing Disparity in Colorectal Cancer Incidence and Mortality among African Americans and Whites: A State’s Experience. Journal of Gastrointestinal Oncology 2011(2)2:85-92.\nLepeak L, Jones NR, Williamson A, LoConte N. Persistence in Breast Cancer Disparities between African Americans and Whites in Wisconsin. WMJ. 2011 March; 110(1):21-25.\nWarren CW, Jones NR, Peruga A, Chauvin J, Baptiste JP, Costa de Silva V, El-Awa F, Tsouros A, Rahman K, Fishburn B, Bettcher DW, Asma S. Global Youth Tobacco Surveillance, 2000–2007. MMWR Surveill Summ. 2008 Jan 25;57(1):1-28.\nWarren CW, Jones NR, Eriksen MP, Asma S. Patterns of global tobacco use in young people and implications for future chronic disease burden in adults. The Lancet, 2006. 367(9512) 749-753.\nFrankenberg E and Jones NR. Self-Rated Health and Mortality: Does the Relationship Extend to a Low Income Setting? Journal of Health and Social Behavior, Volume 45, Number 4, December 2004, pp. 441-452."
  },
  {
    "objectID": "basic.html",
    "href": "basic.html",
    "title": "Basic R",
    "section": "",
    "text": "Why use R?\nR and RStudio have several advantages over statistical software like Stata, SAS, and SPSS.\n\nR can load multiple data sources in multiple formats at the same time.\nR is open source and helper packages are widely developed by users.\nR incorporates version control and collaboration tools like git and GitHub.\nR can output data to any file format and can create reports in HTML, PDF, docx, and pptx format.\nThe RStudio IDE has a nice organization tool called Projects.\n\n\n\nComponent overview\nR is a free and open source statistical computing language. RStudio is an integrated development environment (IDE) that makes using R much easier. You need to install both on your computer to get started.\n\n\nInstalling R, RStudio (UWSC)\n\nOpen Software Center\nClick to install R\nClick to install RStudio\n(Possibly necessary) Open RGui to initialize local folders\nInstall packages\n\n\n\nInstalling R, RStudio (Non-UWSC)\n\nInstall latest R from R’s main site\nInstall RStudio from Posit’s site\nInstall packages\n\n\n\nOrientation to the interface\n\nGrid: Code, Console, Environment, Files\nSpecial views\nPop out code\n\n\n\nHelper packages:\n\ntidyverse - Lots of helpful data manipulation tools\nhaven - Reads and writes SPSS, Stata, csv\nboxr - Posts files to Box\nqualtRics - Reads and processes data from Qualtrics\n\n\n\nImporting/exporting various formats\n\nlibrary(haven)\n\ndf1 <- read_spss(\"./raw/Any SPSS File.sav\")\ndf2 <- read_dta(\"./raw/Any Stata File.dta\")\ndf3 <- read_csv(\"./raw/Any csv File.csv\")\n\nlibrary(readxl)\n\ndf4 <- read_xlsx(\"./raw/Any Excel File Skip First Two Rows.xlsx\", skip=2)\n\n\n\nExample workflow\nOne way of getting new data from Qualtrics/POD, process for delivery, zip, post to Box\n\n# Read survey data file and convert to labeled data\n\ndf <- read_spss(\"./raw/PXXX Wave 1 Data File Raw.sav\")\ndf <- as_factor(df)\n\n# Read sample file and keep important sample data\n\nsam <- read_csv(\"./raw/PXXX Sample File.csv\")\n\nsam <- sam %>% \n  filter(wave == 1) %>% \n  select(csid, dob, zip)\n\n# Clean, remove extra variables, etc\n\ndf <- df %>% \n  filter(!is.na(csid)) %>% \n  select(\n    csid = ExternalReference,\n    Q1:Q35\n  )\n\n# Merge survey with sample data\n\ndf <- left_join(df, sam, by=\"csid\")\n\n# Write data in csv, SPSS, and Stata formats\n\nwrite_csv(df, \"./out/PXXX Interim Data w Sample Info.csv\")\nwrite_sav(df, \"./out/PXXX Interim Data w Sample Info.sav\")\nwrite_dta(df, \"./out/PXXX Interim Data w Sample Info.dta\")\n\n# Zip into folder with date stamp\n\nzip(\n  paste0(\"./pst/PXXX Interim Data delivery for \", Sys.Date(), \".zip\"),\n  c(\n    \"./out/PXXX Interim Data w Sample Info.csv\",\n    \"./out/PXXX Interim Data w Sample Info.sav\",\n    \"./out/PXXX Interim Data w Sample Info.dta\"\n  )\n)\n\n# Refresh Box athenitication\n\nbox_auth()\n\n# Upload date stamp to zip\n\nbox_ul(\n  dir_id = 1234567891234,\n  paste0(\"./pst/PXXX Interim Data delivery for \", Sys.Date(), \".zip\"),\n)"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "cv",
    "section": "",
    "text": "Training and Education\n2001-2003 The RAND Corporation\n\nNational Institute on Aging Post-Doctoral Training Fellowship\n\n1997-2001 University of Pennsylvania\n\nPhD, Demography, 2001\nAM, Demography, 1998\n\nNational Institute on Aging Pre-Doctoral Training Fellowship, 1998-2001.\n1993-1997 Emory University\n\nBA/MA, Sociology, 1997\n\n\n\nWork Experience\n2012-present University of Wisconsin Survey Center\nSenior Project Director\n\nConsults with principal investigators on survey research and sampling methodologies.\nManages and coordinates all aspects of surveys including research development, instrument design, application development, and supervision of survey staff.\nManages and analyzes data using statistical software packages including Stata, R, SAS, SPSS, and ArcGIS; writes technical documentation on survey methodology and responses rates; and provides analysis assistance to principal investigators.\nInternational training and technical assistance in Chad, China (Tibet), Ethiopia, Philippines, and others.\n\n2008-2012 University of Wisconsin – Carbone Cancer Center (UWCCC)\nAssistant Scientist\n\nDirector of Survey Research Shared Service (SRSS), providing consultation and technical assistance to cancer center members and other researchers conducting mail, telephone, web-based, and multi-mode surveys.\nAnalyst for MATCH County Health Rankings in UW Population Health Institute.\nEpidemiologist with Wisconsin Cancer Control and Outreach Program.\nPrincipal investigator with UWCCC Nutritional Epidemiology unit.\nResearch collaborator with faculty and graduate students associated with UW Carbone Cancer Center and the Population Health Institute.\nPrincipal investigator for UWCCC tobacco-related grants including Tobacco Surveillance and Evaluation, Training and Technical Assistance, Wisconsin WINS, and SmokeFree Wisconsin.\n\n2004-2008 CDC-Office on Smoking and Health\nSenior Service Fellow - Statistician/Demographer (GS-13)\n\nHelped coordinate the Global Tobacco Surveillance System (GTSS), a series of school-based surveys conducted in partnership with WHO that includes the Global Youth Tobacco Survey (GYTS), the Global School Personnel Survey (GSPS), the Global Health Professional Students Survey (GHPSS), and the Global Adult Tobacco Survey (GATS).\nProvided logistical and technical support to survey coordinators in over 160 countries.\nTeaching faculty for GTSS training and analysis workshops conducted in 6 WHO regions.\nConsultant in the development of research protocols, survey instruments, and training materials for the GATS fielded in 15 developing countries during 2006-2007, part of the Bloomberg Worldwide Stop Smoking Initiative.\nServed as consultant in the development of research protocols, survey instrument, and training materials for the GHPSS.\nExtensive international experience conducting workshops in Barbados, Burkina Faso, Republic of Congo, Denmark, Egypt, Mexico, Philippines, Costa Rica, Switzerland, Thailand, and others."
  },
  {
    "objectID": "sample_clean.html",
    "href": "sample_clean.html",
    "title": "Sample Cleaning",
    "section": "",
    "text": "dup <- df %>% group_by(email) %>% mutate(n=n()) %>% filter(n>1)"
  },
  {
    "objectID": "sample_clean.html#mcname",
    "href": "sample_clean.html#mcname",
    "title": "Sample Cleaning",
    "section": "McName",
    "text": "McName"
  },
  {
    "objectID": "sample_clean.html#oname",
    "href": "sample_clean.html#oname",
    "title": "Sample Cleaning",
    "section": "O’Name",
    "text": "O’Name"
  },
  {
    "objectID": "sample_clean.html#ii-iii-jr-etc",
    "href": "sample_clean.html#ii-iii-jr-etc",
    "title": "Sample Cleaning",
    "section": "Ii, Iii, jr, etc",
    "text": "Ii, Iii, jr, etc"
  },
  {
    "objectID": "sample_clean.html#po-box-us-hwy",
    "href": "sample_clean.html#po-box-us-hwy",
    "title": "Sample Cleaning",
    "section": "Po Box, Us Hwy",
    "text": "Po Box, Us Hwy"
  },
  {
    "objectID": "sample_clean.html#directionals-senw",
    "href": "sample_clean.html#directionals-senw",
    "title": "Sample Cleaning",
    "section": "Directionals: Se/Nw",
    "text": "Directionals: Se/Nw"
  },
  {
    "objectID": "sample_clean.html#st2nd",
    "href": "sample_clean.html#st2nd",
    "title": "Sample Cleaning",
    "section": "1st/2nd",
    "text": "1st/2nd"
  },
  {
    "objectID": "sample_clean.html#rural-roads-n123e1234",
    "href": "sample_clean.html#rural-roads-n123e1234",
    "title": "Sample Cleaning",
    "section": "Rural roads: N123e1234",
    "text": "Rural roads: N123e1234"
  },
  {
    "objectID": "sample_clean.html#of-du-de",
    "href": "sample_clean.html#of-du-de",
    "title": "Sample Cleaning",
    "section": "Of, Du, De",
    "text": "Of, Du, De"
  }
]