---
title: "Functions"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float: 
        collapsed: false
---

# Toy example

The most challenging thing about writing functions in R is the concept of scoping and environments, mostly meaning what things are called and where they are stored. Many, many tutorials and examples are written by stats or math people or programmers who don't use typical social science data. So you see these toy examples like https://www.tutorialspoint.com/r/r_functions.htm

```{r, eval=FALSE}
    # Create a function with arguments.
    new.function <- function(a,b,c) {
       result <- a * b + c
       print(result)
    }

    # Call the function by position of arguments.
    new.function(5,3,11)
```

So simple! But nobody we work with needs or writes functions like that. With structured data, functions are harder to write because R doesn't want you to make a mistake by referring to something in a different scope or environment. It used to be very ugly to code functions with our kind of data, but fairly recently, the tidyverse people came up with using double curly brackets to make it less ugly.

[How do curly brackets work?](https://stackoverflow.com/questions/64065003/how-do-double-curly-brackets-work-in-dplyr)

One commenter covers hours of frustration:

> *Ronak, so the {{}} is used to replace the enquo() and !! operators?*

Hopefully, you'll never have to know what that means, but if you are curious, this explains:

[rlang 0.4.0 release notes](https://www.tidyverse.org/blog/2019/06/rlang-0-4-0/)

# Double curly brackets

How does this look in practice? Here's a function I wrote to create nice looking crosstabs:

```{r, eval=FALSE}
    ctab <- function(x,y) {

      tmp <- df %>%
        filter(!is.na({{x}}))

      tmp <- droplevels(tmp)

      tmp2 <- tabyl(tmp, {{x}}, {{y}}) %>%
        adorn_totals(c("col", "row")) %>%
        adorn_percentages("col") %>%
        adorn_pct_formatting() %>%
        adorn_ns()

      tmp2 <- kable(tmp2)

      return(tmp2)
    }
```

This combines a little cleaning I wanted to do on a lot of variables (removing blanks, dropping unused factor levels so you don't get a lot of 0s in the table) and uses a nice function tabyl() from the janitor package to add n/% and kable() to make a formatted table. You can now write crosstabs like this

> ctab(Q5, Q12r)

where Q5 is some Yes/No question and Q12r is recoded categorical age and the output looks like this:

| Q5     | \<14        | 14-16        | 17+         | Total        |
|:-------|:------------|:-------------|:------------|:-------------|
| Yes    | 94.7% (18)  | 88.2% (105)  | 96.4% (54)  | 91.2% (177)  |
| No     | 5.3% (1)    | 5.0% (6)     | 1.8% (1)    | 4.1% (8)     |
| Unsure | 0.0% (0)    | 6.7% (8)     | 1.8% (1)    | 4.6% (9)     |
| Total  | 100.0% (19) | 100.0% (119) | 100.0% (56) | 100.0% (194) |

You could clean more by removing the Unsures from all tables that use this function by adding filter({{x}} != "Unsure" after the line that removes the missings, etc.

That function is a little quick and dirty because it assumes you always want to do crosstabs using a data object called "df". If you had 7 data files loaded and wanted to be able to make crosstabs with several in a report, you could add a parameter for the data name like this

```{r, eval=FALSE}
    ctab <- function(df, x, y) {

      tmp <- df %>%
        filter(!is.na({{x}}))

      tmp <- droplevels(tmp)

      tmp2 <- tabyl(tmp, {{x}}, {{y}}) %>%
        adorn_totals(c("col", "row")) %>%
        adorn_percentages("col") %>%
        adorn_pct_formatting() %>%
        adorn_ns()

      tmp2 <- kable(tmp2)

      return(tmp2)
    }
```

The function would be called with

> ctab(**df3**, Q5, Q12r)
>
> ctab(**df4**, Q5, Q12r)

and so on to use on a specific data file.

# Using functions with functions and loops

And you can also call your function from other functions. Or you can use a loop to cycle through a bunch of variables. The following would print the function for all variables from the 2nd to the end in data file df (make Q12r the first variable so you don't get a Q12r by Q12r line).

```{r, eval=FALSE}
    for(i in 2:length(df)) {
      tmp <- paste0("ctab(df2, ", names(df)[i], ", Q12r)")
      cat(tmp, "\n")
    }
```

Gives you this:

>     ctab(df, Q2, Q12r) 
>     ctab(df, Q3, Q12r)
>     ctab(df, Q4, Q12r)
>     ctab(df, Q5, Q12r)
>     ctab(df, Q6, Q12r)
>     ctab(df, Q7, Q12r)
>     ctab(df, Q8, Q12r)
>     ctab(df, Q9, Q12r) 

...

Or you can can get fancy by adding the variable label too and now you basically have a report:

```{r, eval=FALSE}
    for(i in 2:length(df)) {
      tmp1 <- attr(df[[i]], "label")
      tmp2 <- paste0("ctab(df, ", names(df)[i], ", Q12r)")
      cat(tmp1, "\n\n", tmp2, "\n\n")  # \n is a line break
    }
```

Output:

> Do you have a transition plan?
>
>     ctab(df, Q3, Q12r)
>
> Did you help make your transition plan?
>
>     ctab(df, Q4, Q12r)
>
> Do you think having a transition plan is helpful?
>
>     ctab(df, Q5, Q12r)

Last thing, there is a thing called Extract Function in the Code menu. In theory, you should be able to highlight a few lines of code that do something useful and it will just rewrite the code as a function. It works pretty well, but usually you would end up reorganizing your initial approach to write a function anyway, so I don't find it too helpful.

# Resources

Reasonably accessible\
https://dplyr.tidyverse.org/articles/programming.html

More details on the {{ }} functionality\
https://www.tidyverse.org/blog/2019/06/rlang-0-4-0/

Hadley's function section - Still too complex for me\
https://r4ds.had.co.nz/functions.html
